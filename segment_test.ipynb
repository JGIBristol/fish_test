{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Just to be sure...\n",
    "\n",
    "\"\"\"\n",
    "import sys\n",
    "from jupyter_server import serverapp\n",
    "\n",
    "print(f\"Using python at {sys.executable}\")\n",
    "print(f\"Python version {sys.version}\")\n",
    "\n",
    "for server in serverapp.list_running_servers():\n",
    "    print(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display two images I'm using for training\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from dev import plot, util\n",
    "\n",
    "folder = os.path.join(util.userconf()[\"rdsf_dir\"], \"Yushi/Videos/theta_1/Code/segmenter/notebooks/projects/20180701_cell_segment/\")\n",
    "img_path = folder + \"jaw_raw_image.npy\"\n",
    "mask_path = folder + \"jaw_labels.npy\"\n",
    "\n",
    "img = np.load(img_path)\n",
    "mask = np.load(mask_path)\n",
    "\n",
    "# Convert the mask to labels\n",
    "mask[(mask < 32) & (mask > 0)] = 1\n",
    "mask[mask >= 32] = 2\n",
    "\n",
    "img = np.transpose(img, (2, 0, 1))\n",
    "mask = np.transpose(mask, (2, 0, 1))\n",
    "\n",
    "plot.plot_arr(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ignore all that and use a brain MRI dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch.utils\n",
    "import torchio as tio\n",
    "from dev import image_io\n",
    "\n",
    "transform = image_io.random_transforms()\n",
    "\n",
    "subjectdataset = tio.datasets.ixi.IXITiny(\n",
    "    root=\"tmp_data/\", transform=transform, download=True\n",
    ")\n",
    "\n",
    "# This is slow and bad\n",
    "indices = np.arange(len(subjectdataset))\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx, test_idx = np.split(\n",
    "    indices, [int(0.8 * len(indices)), len(indices) - 1]\n",
    ")\n",
    "print(len(train_idx), len(val_idx), len(test_idx))\n",
    "\n",
    "train_data = tio.SubjectsDataset([subjectdataset[i] for i in train_idx])\n",
    "val_data = tio.SubjectsDataset([subjectdataset[i] for i in test_idx])\n",
    "test_data = tio.SubjectsDataset([subjectdataset[i] for i in train_idx])\n",
    "\n",
    "del subjectdataset\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot.plot_arr(\n",
    "    image_io.pytorch2img(train_data[0].image.data.squeeze()),\n",
    "    image_io.pytorch2img(train_data[0].label.data.squeeze()),\n",
    ")\n",
    "fig.suptitle(\"Randomly Transformed\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create a DataLoader\"\"\"\n",
    "\n",
    "import torch\n",
    "from dev.util import userconf\n",
    "\n",
    "uconf = userconf()\n",
    "patch_size = [int(x) for x in uconf[\"patch_size\"].split(\",\")]\n",
    "print(f\"Patch size: {patch_size}\")\n",
    "\n",
    "\n",
    "def dataloader(dataset: tio.SubjectsDataset):\n",
    "    # Choose the probability of patches being centred on each value\n",
    "    label_probs = {0: 1, 1: 1, 2: 1}\n",
    "    patch_sampler = tio.LabelSampler(\n",
    "        patch_size=patch_size, label_probabilities=label_probs\n",
    "    )\n",
    "    patches = tio.Queue(\n",
    "        dataset,\n",
    "        max_length=10000,\n",
    "        samples_per_volume=6,\n",
    "        sampler=patch_sampler,\n",
    "        num_workers=10,\n",
    "    )\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        patches,\n",
    "        batch_size=uconf[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "train_loader = dataloader(train_data)\n",
    "val_loader = dataloader(val_data)\n",
    "test_loader = dataloader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load a model\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from dev.segmentation import model as lib_model\n",
    "\n",
    "model = lib_model.model()\n",
    "# lib_model.draw_model(model, \"model.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create an optimiser + choose a loss function\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from monai.losses import TverskyLoss\n",
    "\n",
    "optimiser = lib_model.optimiser(model)\n",
    "loss = TverskyLoss(include_background=True, to_onehot_y=True, alpha=0.2)\n",
    "\n",
    "optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cpu\":\n",
    "    # Yellow text\n",
    "    yellow = \"\\033[33m\"\n",
    "    clear = \"\\033[0m\"\n",
    "    warnings.warn(f\"{yellow}This might not be what you want!{clear}\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss, val_loss = lib_model.train(\n",
    "    model,\n",
    "    optimiser,\n",
    "    loss,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device=device,\n",
    "    epochs=100,\n",
    "    lr_scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, patience=2),\n",
    "    notebook=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss, label=\"Train\")\n",
    "plt.plot(val_loss, label=\"Validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Show the result on the test data\n",
    "\n",
    "\"\"\"\n",
    "print(test_loader)\n",
    "test_patch = next(iter(test_loader)) if not \"test_patch\" in locals() else test_patch\n",
    "\n",
    "test_data = test_patch[\"image\"][\"data\"]\n",
    "test_label = test_patch[\"label\"][\"data\"]\n",
    "\n",
    "prediction = model(test_data.to(device)).to(\"cpu\").detach()\n",
    "\n",
    "# Convert one-hot to labels\n",
    "prediction = prediction.argmax(dim=1)\n",
    "\n",
    "# Convert to numpy\n",
    "test_data = test_data.squeeze(1).numpy()\n",
    "test_label = test_label.squeeze(1).numpy()\n",
    "\n",
    "# Extract just one patch\n",
    "i = 0\n",
    "prediction = prediction[i]\n",
    "test_data = test_data[i]\n",
    "test_label = test_label[i]\n",
    "\n",
    "fig, _ = plot.plot_arr(test_data, prediction)\n",
    "fig.suptitle(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig, _ = plot.plot_arr(test_data, test_label)\n",
    "fig.suptitle(\"Ground Truth\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
